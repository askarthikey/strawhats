{"ids": ["699d3cd6fc47dbc29db48a11", "699d3cd6fc47dbc29db48a12", "699d3cd6fc47dbc29db48a13", "699d3cd6fc47dbc29db48a14", "699d3cd6fc47dbc29db48a15", "699d3ce6fc47dbc29db48a17", "699d3ce6fc47dbc29db48a18", "699d3ce6fc47dbc29db48a19", "699d3ce6fc47dbc29db48a1a", "699d3ce6fc47dbc29db48a1b", "699d3ce6fc47dbc29db48a1c", "699d3ce6fc47dbc29db48a1d", "699d3ce6fc47dbc29db48a1e", "699d3ce6fc47dbc29db48a1f", "699d3ce6fc47dbc29db48a20", "699d3ce6fc47dbc29db48a21", "699d3ce6fc47dbc29db48a22", "699d3ce6fc47dbc29db48a23", "699d3ce6fc47dbc29db48a24", "699d3ce6fc47dbc29db48a25", "699d3ce6fc47dbc29db48a26", "699d3ce6fc47dbc29db48a27", "699d3ce6fc47dbc29db48a28", "699d3ce6fc47dbc29db48a29", "699d3ce6fc47dbc29db48a2a", "699d3ce6fc47dbc29db48a2b", "699d3ce6fc47dbc29db48a2c", "699d3ce6fc47dbc29db48a2d", "699d3ce6fc47dbc29db48a2e", "699d3ce6fc47dbc29db48a2f", "699d3ce6fc47dbc29db48a30", "699d3ce6fc47dbc29db48a31", "699d3ce6fc47dbc29db48a32", "699d3ce6fc47dbc29db48a33", "699d3ce6fc47dbc29db48a34", "699d3ce6fc47dbc29db48a35", "699d3ce6fc47dbc29db48a36", "699d3ce6fc47dbc29db48a37", "699d3ce6fc47dbc29db48a38", "699d3ce6fc47dbc29db48a39", "699d3ce6fc47dbc29db48a3a", "699d3ce6fc47dbc29db48a3b", "699d3ce6fc47dbc29db48a3c", "699d3ce6fc47dbc29db48a3d", "699d3ce6fc47dbc29db48a3e", "699d3ce6fc47dbc29db48a3f", "699d3ce6fc47dbc29db48a40", "699d3ce6fc47dbc29db48a41", "699d3ce6fc47dbc29db48a42", "699d3ce6fc47dbc29db48a43", "699d3ce6fc47dbc29db48a44", "699d3ce6fc47dbc29db48a45", "699d3ce6fc47dbc29db48a46", "699d3ce6fc47dbc29db48a47", "699d3ce6fc47dbc29db48a48", "699d3ce6fc47dbc29db48a49", "699d3ce6fc47dbc29db48a4a", "699d3ce6fc47dbc29db48a4b", "699d3ce6fc47dbc29db48a4c", "699d3ce6fc47dbc29db48a4d", "699d3ce6fc47dbc29db48a4e", "699d3ce6fc47dbc29db48a4f", "699d3ce6fc47dbc29db48a50", "699d3ce6fc47dbc29db48a51", "699d3ce6fc47dbc29db48a52", "699d3ce6fc47dbc29db48a53", "699d3ce6fc47dbc29db48a54", "699d3ce6fc47dbc29db48a55", "699d3ce6fc47dbc29db48a56", "699d3ce6fc47dbc29db48a57", "699d3ce6fc47dbc29db48a58", "699d3ce6fc47dbc29db48a59", "699d3ce6fc47dbc29db48a5a", "699d3ce6fc47dbc29db48a5b", "699d3ce6fc47dbc29db48a5c", "699d3ce6fc47dbc29db48a5d", "699d3ce6fc47dbc29db48a5e", "699d3ce6fc47dbc29db48a5f", "699d3ce6fc47dbc29db48a60", "699d3ce6fc47dbc29db48a61", "699d3ce6fc47dbc29db48a62", "699d3ce6fc47dbc29db48a63", "699d3ce6fc47dbc29db48a64", "699d3ce6fc47dbc29db48a65", "699d3ce6fc47dbc29db48a66", "699d3ce6fc47dbc29db48a67", "699d3ce6fc47dbc29db48a68", "699d3ce6fc47dbc29db48a69", "699d3ce6fc47dbc29db48a6a", "699d3ce6fc47dbc29db48a6b", "699d3ce6fc47dbc29db48a6c", "699d3ce6fc47dbc29db48a6d", "699d3ce6fc47dbc29db48a6e", "699d3ce6fc47dbc29db48a6f", "699d3ce6fc47dbc29db48a70", "699d3ce6fc47dbc29db48a71", "699d3ce6fc47dbc29db48a72", "699d3ce6fc47dbc29db48a73", "699d3ce6fc47dbc29db48a74", "699d3ce6fc47dbc29db48a75", "699d3ce6fc47dbc29db48a76", "699d3ce6fc47dbc29db48a77", "699d3ce6fc47dbc29db48a78", "699d3ce6fc47dbc29db48a79", "699d3ce6fc47dbc29db48a7a", "699d3ce6fc47dbc29db48a7b", "699d3ce6fc47dbc29db48a7c", "699d3ce6fc47dbc29db48a7d", "699d3ce6fc47dbc29db48a7e", "699d3ce6fc47dbc29db48a7f", "699d3ce6fc47dbc29db48a80", "699d3ce6fc47dbc29db48a81", "699d3ce6fc47dbc29db48a82", "699d3ce6fc47dbc29db48a83"], "metadata": [{"paper_id": "699d3cd2fc47dbc29db48a10", "chunk_index": 0, "page_number": 1, "text_preview": "arXiv:1201.0490v4  [cs.LG]  5 Jun 2018\nJournal of Machine Learning Research 12 (2011) 2825-2830\nSubmitted 3/11; Revised 8/11; Published 10/11\nScikit-learn: Machine Learning in Python\nFabian Pedregosa\n", "paper_title": "Scikit-learn: Machine Learning in Python"}, {"paper_id": "699d3cd2fc47dbc29db48a10", "chunk_index": 1, "page_number": 2, "text_preview": "Introduction\nThe Python programming language is establishing itself as one of the most popular lan-\nguages for scienti\ufb01c computing. Thanks to its high-level interactive nature and its maturing\necosyst", "paper_title": "Scikit-learn: Machine Learning in Python"}, {"paper_id": "699d3cd2fc47dbc29db48a10", "chunk_index": 2, "page_number": 3, "text_preview": "Numpy\u2019s view-based memory model limits copies, even when binding with compiled code\n(Van der Walt et al., 2011). It also provides basic arithmetic operations. Scipy: e\ufb03cient algorithms for linear alge", "paper_title": "Scikit-learn: Machine Learning in Python"}, {"paper_id": "699d3cd2fc47dbc29db48a10", "chunk_index": 3, "page_number": 4, "text_preview": "predict, score,\nor transform are then delegated to the tuned estimator. This object can therefore be used\ntransparently as any other estimator. Cross validation can be made more e\ufb03cient for certain\nes", "paper_title": "Scikit-learn: Machine Learning in Python"}, {"paper_id": "699d3cd2fc47dbc29db48a10", "chunk_index": 4, "page_number": 5, "text_preview": "References\nD. Albanese, G. Merler, S.and Jurman, and R. Visintainer. MLPy: high-performance\nPython package for predictive modeling. In NIPS, MLOSS workshop, 2008. C.C. Chang\nand\nC.J. Lin. LIBSVM:\na\nli", "paper_title": "Scikit-learn: Machine Learning in Python"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 0, "page_number": 1, "text_preview": "Deep Learning in Neural Networks: An Overview\nTechnical Report IDSIA-03-14 / arXiv:1404.7828 v4 [cs.NE] (88 pages, 888 references)\nJ\u00a8urgen Schmidhuber\nThe Swiss AI Lab IDSIA\nIstituto Dalle Molle di St", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 1, "page_number": 2, "text_preview": ". . . . . . . . . 8\n5\nSupervised NNs, Some Helped by Unsupervised NNs\n8\n5.1\nEarly NNs Since the 1940s (and the 1800s)\n. . . . . . . . . . . . . . . . . . . . . . 9\n5.2\nAround 1960: Visual Cortex Provi", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 2, "page_number": 2, "text_preview": ". . . . . . . 23\n5.19 2011: MPCNNs on GPU Achieve Superhuman Vision Performance\n. . . . . . . . . 23\n5.20 2011: Hessian-Free Optimization for RNNs . . . . . . . . . . . . . . . . . . . . . . 24\n5.21 2", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 3, "page_number": 3, "text_preview": ". . . . . . . . . . . . . 31\n6.4\nRL Facilitated by Deep UL in FNNs and RNNs . . . . . . . . . . . . . . . . . . . . 31\n6.5\nDeep Hierarchical RL (HRL) and Subgoal Learning with FNNs and RNNs . . . . . ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 4, "page_number": 4, "text_preview": "What\nchanges to them improve performance? This has been called the fundamental credit assignment prob-\nlem (Minsky, 1963). There are general credit assignment methods for universal problem solvers tha", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 5, "page_number": 4, "text_preview": "Unlike traditional methods for automatic sequential program synthesis (e.g., Waldinger and Lee, 1969;\nBalzer, 1985; Soloway, 1986; Deville and Lau, 1994), RNNs can learn programs that mix sequential\na", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 6, "page_number": 5, "text_preview": "For example, in the non-input case we may have xt =\nft(nett) with real-valued nett = P\nk\u2208int xkwv(k,t) (additive case) or nett = Q\nk\u2208int xkwv(k,t)\n(multiplicative case), where ft is a typically nonlin", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 7, "page_number": 6, "text_preview": "Depending on the\napplication, they may have a Potential Direct Causal Connection (PDCC) expressed by the Boolean\npredicate pdcc(p, q), which is true if and only if p \u2208inq. Then the 2-element list (p, ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 8, "page_number": 6, "text_preview": "6.1. 6\nto a precise answer, let me just de\ufb01ne for the purposes of this overview: problems of depth > 10\nrequire Very Deep Learning. The dif\ufb01culty of a problem may have little to do with its depth. Som", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 9, "page_number": 7, "text_preview": "4.2\nUnsupervised Learning (UL) Facilitating SL and RL\nAnother recurring theme is how UL can facilitate both SL (Sec. 5) and RL (Sec. 6). UL (Sec. 5.6.4)\nis normally used to encode raw incoming data su", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 10, "page_number": 8, "text_preview": "In the NN case, the MDL princi-\nple suggests that low NN weight complexity corresponds to high NN probability in the Bayesian\nview (e.g., MacKay, 1992; Buntine and Weigend, 1991; Neal, 1995; De Freita", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 11, "page_number": 9, "text_preview": "Sec. 5.5\nuses the notation of Sec. 2 to compactly describe a central algorithm of DL, namely, backpropagation\n(BP) for supervised weight-sharing FNNs and RNNs. It also summarizes the history of BP 196", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 12, "page_number": 9, "text_preview": "In a sense NNs have been around even longer, since early supervised NNs were essentially variants\nof linear regression methods going back at least to the early 1800s (e.g., Legendre, 1805; Gauss, 1809", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 13, "page_number": 10, "text_preview": "The resulting 2D array of subsequent activation\nevents of this unit can then provide inputs to higher-level units, and so on. Due to massive weight\nreplication (Sec. 2), relatively few parameters (Sec", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 14, "page_number": 11, "text_preview": "5.1) discouraged some researchers\nfrom further studying NNs. Explicit, ef\ufb01cient error backpropagation (BP) in arbitrary, discrete, possibly sparsely connected,\nNN-like networks apparently was \ufb01rst des", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 15, "page_number": 12, "text_preview": "No-\ntably, most contest-winning NNs up to 2014 (Sec. 5.12, 5.14, 5.17, 5.19, 5.21, 5.22) did not augment\nsupervised BP by some sort of unsupervised learning as discussed in Sec. 5.7, 5.10, 5.15. 5.6\nL", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 16, "page_number": 12, "text_preview": "12\nInput patterns enter the \ufb01rst FNN and are propagated \u201cup\u201d. Desired outputs (targets) enter the \u201coppo-\nsite\u201d FNN and are propagated \u201cdown\u201d. Using a local learning rule, each layer in each net tries ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 17, "page_number": 13, "text_preview": "The local gradient can be normalized based on the NN architecture (Schraudolph and Sejnowski,\n1996), through a diagonalized Hessian approach (Becker and Le Cun, 1989), or related ef\ufb01cient meth-\nods (S", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 18, "page_number": 14, "text_preview": "5.3, 5.11), input pruning (Moody, 1992;\nRefenes et al., 1994), unit pruning (e.g., Ivakhnenko, 1968, 1971; White, 1989; Mozer and Smolen-\nsky, 1989; Levin et al., 1994), weight pruning, e.g., optimal ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 19, "page_number": 14, "text_preview": "Many UL methods are designed to maximize entropy-related, information-theoretic (Boltzmann,\n1909; Shannon, 1948; Kullback and Leibler, 1951) objectives (e.g., Linsker, 1988; Barlow et al., 1989;\nMacKa", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 20, "page_number": 15, "text_preview": "Methods for deeper UL FNNs include hierarchical\n(Sec. 4.3) self-organizing Kohonen maps (e.g., Koikkalainen and Oja, 1990; Lampinen and Oja, 1992;\nVersino and Gambardella, 1996; Dittenbach et al., 200", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 21, "page_number": 16, "text_preview": "Compare an early sur-\nvey (Hinton, 1989) and the somewhat related Recursive Auto-Associative Memory (RAAM) (Pollack,\n1988, 1990; Melnik et al., 2000), originally used to encode sequential linguistic s", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 22, "page_number": 16, "text_preview": "See also (Hochreiter et al., 2001a; Ti\u02c7no and Hammer, 2004). Over the years, several ways of partially\novercoming the Fundamental Deep Learning Problem were explored:\nI A Very Deep Learner of 1991 (th", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 23, "page_number": 17, "text_preview": "From then on, only unexpected inputs\n(errors) convey new information and get fed to the next higher RNN which thus ticks on a slower, self-\norganising time scale. It can easily be shown that no inform", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 24, "page_number": 18, "text_preview": "Clockwork RNNs (Koutn\u00b4\u0131k et al., 2014) also consist of interacting RNN modules with different clock\nrates, but do not use UL to set those rates. Stacks of RNNs were used in later work on SL with great", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 25, "page_number": 19, "text_preview": "5.10), dealing\nwith very deep problems (Sec. 3) (e.g., Gers et al., 2002). The basic LSTM idea is very simple. Some of the units are called Constant Error Carousels\n(CECs). Each CEC uses as an activat", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 26, "page_number": 19, "text_preview": "Similar for context-sensitive languages\n(CSLs) (e.g., Chalup and Blair, 2003). LSTM generalized well though, requiring only the 30 shortest\nexemplars (n \u226410) of the CSL anbncn to correctly predict the", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 27, "page_number": 20, "text_preview": "5.22). In the early 2000s, speech recognition was dominated by HMMs combined with FNNs (e.g.,\nBourlard and Morgan, 1994). Nevertheless, when trained from scratch on utterances from the TIDIG-\nITS spee", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 28, "page_number": 21, "text_preview": "Nevertheless, at least in certain domains, NNs outperformed other\ntechniques. A Bayes NN (Neal, 2006) based on an ensemble (Breiman, 1996; Schapire, 1990; Wolpert, 1992;\nHashem and Schmeiser, 1992; Ue", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 29, "page_number": 21, "text_preview": "Each RBM perceives pattern representations from the level below and learns to encode them in un-\nsupervised fashion. At least in theory under certain assumptions, adding more layers improves a\nbound o", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 30, "page_number": 22, "text_preview": "GPUs or graphics cards have become more and more\nimportant for DL in subsequent years (Sec. 5.18\u20135.22). In 2007, BP (Sec. 5.5) was applied for the \ufb01rst time (Ranzato et al., 2007) to Neocognitron-\nins", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 31, "page_number": 23, "text_preview": "5.8) record of 0.35% error rate was set by good old BP (Sec. 5.5)\nin deep but otherwise standard NNs (Ciresan et al., 2010), using neither unsupervised pre-training\n(e.g., Sec. 5.7, 5.10, 5.15) nor co", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 32, "page_number": 23, "text_preview": "An ensemble of GPU-MPCNNs was the \ufb01rst system to achieve superhuman visual pattern recog-\nnition (Ciresan et al., 2011b, 2012b) in a controlled competition, namely, the IJCNN 2011 traf\ufb01c\nsign recognit", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 33, "page_number": 24, "text_preview": "5.6.2) can alleviate the Fundamental Deep Learn-\ning Problem (Sec. 5.9) in RNNs, outperforming standard gradient-based LSTM RNNs (Sec. 5.13) on\nseveral tasks. Compare other RNN algorithms (Jaeger, 200", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 34, "page_number": 25, "text_preview": "Given electron microscopy images of stacks of thin slices of animal\nbrains, the goal is to build a detailed 3D model of the brain\u2019s neurons and dendrites. But human\nexperts need many hours and days an", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 35, "page_number": 25, "text_preview": "An LSTM RNN was used to estimate the state posteriors of an HMM; this system beat the previous\nstate of the art in large vocabulary speech recognition (Sak et al., 2014b,a). Another LSTM RNN with\nhund", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 36, "page_number": 26, "text_preview": "5.13, 5.17, 5.21, 5.22), or\n(b) feedforward GPU-MPCNNs (2011, Sec. 5.19, 5.21, 5.22) based on CNNs (1979, Sec. 5.4) with\nMP (1992, Sec. 5.11) trained through BP (1989\u20132007, Sec. 5.8, 5.16). Exceptions", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 37, "page_number": 27, "text_preview": "Denoising AEs later used a similar procedure (Vin-\ncent et al., 2008). Dropout (Hinton et al., 2012b; Ba and Frey, 2013) removes units from NNs during training to\nimprove generalisation. Some view it ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 38, "page_number": 27, "text_preview": "4.4, 5.6.3), becoming fast and slim when necessary. One may\npenalize the task-speci\ufb01c total length of connections (e.g., Legenstein and Maass, 2002; Schmidhuber,\n2012, 2013b; Clune et al., 2013) and c", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 39, "page_number": 28, "text_preview": "5.26\nDL with Spiking Neurons? Many recent DL results pro\ufb01t from GPU-based traditional deep NNs, e.g., Sec. 5.16\u20135.19. Current\nGPUs, however, are little ovens, much hungrier for energy than biological ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 40, "page_number": 29, "text_preview": "Here we add a\ndiscussion of DL FNNs and RNNs for RL. It will be shorter than the discussion of FNNs and RNNs\nfor SL and UL (Sec. 5), re\ufb02ecting the current size of the various \ufb01elds. Without a teacher,", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 41, "page_number": 29, "text_preview": "To allow for memories of previous events in partially observable worlds (Sec. 6.3), the most gen-\neral variant of this technique uses RNNs instead of FNNs to implement both M and C (Schmidhuber,\n1990d", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 42, "page_number": 30, "text_preview": "The original RL goal (\ufb01nd weights that maximize the sum of all\nrewards of an episode) is replaced by an equivalent set of alternative goals set by a real-valued value\nfunction V de\ufb01ned on input events", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 43, "page_number": 30, "text_preview": "Even bet-\nter results are achieved by using (slow) Monte Carlo tree planning to train comparatively fast deep\nNNs (Guo et al., 2014). Compare RBM-based RL (Sallans and Hinton, 2004) with high-dimensio", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 44, "page_number": 31, "text_preview": "5.7, 5.15). RL combined with UL\nbased on Slow Feature Analysis (Wiskott and Sejnowski, 2002; Kompella et al., 2012) enabled a real\nhumanoid robot to learn skills from raw high-dimensional video stream", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 45, "page_number": 32, "text_preview": "6.6\nDeep RL by Direct NN Search / Policy Gradients / Evolution\nNot quite as universal as the methods of Sec. 6.8, yet both practical and more general than most\ntraditional RL algorithms (Sec. 6.2), ar", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 46, "page_number": 32, "text_preview": "6.2) and EAs (e.g., Whiteson and Stone, 2006). Since RNNs are general computers, RNN evolution is like GP in the sense that it can evolve\ngeneral programs. Unlike sequential programs learned by tradit", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 47, "page_number": 33, "text_preview": "This helps to avoid over\ufb01tting (compare Sec. 5.6.3, 5.24) and is\nclosely related to the topics of regularisation and MDL (Sec. 4.4). A general approach (Schmidhuber, 1997) for both SL and RL seeks to ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 48, "page_number": 34, "text_preview": "Here I won\u2019t further discuss universal\nRL methods, which go beyond what is usually called DL. 7\nConclusion and Outlook\nDeep Learning (DL) in Neural Networks (NNs) is relevant for Supervised Learning (", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 49, "page_number": 34, "text_preview": "5.24). (2) Numerous neurons are sparsely connected in a compact 3D volume by many short-range and\nfew long-range connections (much like microchips in traditional supercomputers). Often neighbour-\ning ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 50, "page_number": 35, "text_preview": "A learning rule for asynchronous perceptrons with feedback in a combinatorial\nenvironment. In IEEE 1st International Conference on Neural Networks, San Diego, volume 2,\npages 609\u2013618. Almeida, L. B., ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 51, "page_number": 36, "text_preview": "Ba, J. and Frey, B. (2013). Adaptive dropout for training deep neural networks. In Advances in Neural\nInformation Processing Systems (NIPS), pages 3084\u20133092. Baird, H. (1990). Document image defect mo", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 52, "page_number": 37, "text_preview": "Ballard, D. H. (1987). Modular learning in neural networks. In Proc. AAAI, pages 279\u2013284. Baluja, S. (1994). Population-based incremental learning:\nA method for integrating genetic\nsearch based functi", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 53, "page_number": 38, "text_preview": "(1763). An essay toward solving a problem in the doctrine of chances. Philosophical\nTransactions of the Royal Society of London, 53:370\u2013418. Communicated by R. Price, in a letter\nto J. Canton. Becker,", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 54, "page_number": 39, "text_preview": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(8):1798\u20131828. Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007). Greedy layer-wise training of deep\nnetworks. In Cowa", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 55, "page_number": 40, "text_preview": "Bod\u00b4en, M. and Wiles, J. (2000). Context-free and context-sensitive dynamics in recurrent neural\nnetworks. Connection Science, 12(3-4):197\u2013210. Bodenhausen, U. and Waibel, A. (1991). The Tempo 2 algor", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 56, "page_number": 41, "text_preview": "(1965). A class of methods for solving nonlinear simultaneous equations. Math. Comp, 19(92):577\u2013593. Brueckner, R. and Schulter, B. (2014). Social signal classi\ufb01cation using deep BLSTM recurrent neura", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 57, "page_number": 42, "text_preview": "(2006). High performance convolutional neural networks for\ndocument processing. In International Workshop on Frontiers in Handwriting Recognition. Chen, K. and Salman, A. (2011). Learning speaker-spec", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 58, "page_number": 43, "text_preview": "(2013). Multi-column deep neural networks for of\ufb02ine handwrit-\nten Chinese character classi\ufb01cation. Technical report, IDSIA. arXiv:1309.0261. Cliff, D. T., Husbands, P., and Harvey, I. (1993). Evolvin", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 59, "page_number": 43, "text_preview": "43\nDahl, G. E., Sainath, T. N., and Hinton, G. E. (2013). Improving deep neural networks for LVCSR\nusing recti\ufb01ed linear units and dropout. In IEEE International Conference on Acoustics, Speech\nand Si", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 60, "page_number": 44, "text_preview": "L., editors, Advances in Neural Information Processing Systems (NIPS) 5, pages\n580\u2013587. Morgan Kaufmann. Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum likelihood from incomplete data", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 61, "page_number": 45, "text_preview": "Journal of Mathematical\nAnalysis and Applications, 5(1):30\u201345. Dreyfus, S. E. (1973). The computational solution of optimal control problems with time lag. IEEE\nTransactions on Automatic Control, 18(4", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 62, "page_number": 46, "text_preview": "Morgan Kaufmann. Falconbridge, M. S., Stamps, R. L., and Badcock, D. R. (2006). A simple Hebbian/anti-Hebbian\nnetwork learns the sparse, independent components of natural images. Neural Computation,\n1", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 63, "page_number": 47, "text_preview": "Fischer, A. and Igel, C. (2014). Training restricted Boltzmann machines: An introduction. Pattern\nRecognition, 47:25\u201339. FitzHugh, R. (1961). Impulses and physiological states in theoretical models of", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 64, "page_number": 48, "text_preview": "Fukushima, K. (1980). Neocognitron: A self-organizing neural network for a mechanism of pattern\nrecognition unaffected by shift in position. Biological Cybernetics, 36(4):193\u2013202. Fukushima, K. (2011)", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 65, "page_number": 49, "text_preview": "Gherrity, M. (1989). A learning algorithm for analog fully recurrent neural networks. In IEEE/INNS\nInternational Joint Conference on Neural Networks, San Diego, volume 1, pages 643\u2013644. Girshick, R., ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 66, "page_number": 50, "text_preview": "Gomez, F. J., Schmidhuber, J., and Miikkulainen, R. (2008). Accelerated neural evolution through\ncooperatively coevolved synapses. Journal of Machine Learning Research, 9(May):937\u2013965. Gomi, H. and Ka", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 67, "page_number": 51, "text_preview": "(2009). A\nnovel connectionist system for improved unconstrained handwriting recognition. IEEE Transac-\ntions on Pattern Analysis and Machine Intelligence, 31(5). Graves, A., Mohamed, A.-R., and Hinton", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 68, "page_number": 52, "text_preview": "In Lippman, D. S., Moody, J. E., and Touretzky, D. S., editors, Advances in\nNeural Information Processing Systems (NIPS) 4, pages 471\u2013479. Morgan Kaufmann. Hadamard, J. (1908). M\u00b4emoire sur le probl`e", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 69, "page_number": 53, "text_preview": "Wiley Online Library. Hebb, D. O. (1949). The Organization of Behavior. Wiley, New York. Hecht-Nielsen, R. (1989). Theory of the backpropagation neural network. In International Joint\nConference on Ne", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 70, "page_number": 54, "text_preview": "MIT Press. Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. R. (2012b). Improving neural networks by preventing co-adaptation of feature detectors. Technical Report\n", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 71, "page_number": 54, "text_preview": "Holland, J. H. (1975). Adaptation in Natural and Arti\ufb01cial Systems. University of Michigan Press,\nAnn Arbor. Honavar, V. and Uhr, L. (1993). Generative learning structures and processes for generalize", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 72, "page_number": 55, "text_preview": "IEEE. Igel, C. and H\u00a8usken, M. (2003). Empirical evaluation of the improved Rprop learning algorithm. Neurocomputing, 50(C):105\u2013123. Ikeda, S., Ochiai, M., and Sawaragi, Y. (1976). Sequential GMDH alg", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 73, "page_number": 56, "text_preview": "Jacob, C., Lindenmayer, A., and Rozenberg, G. (1994). Genetic L-System Programming. In Parallel\nProblem Solving from Nature III, Lecture Notes in Computer Science. Jacobs, R. A. (1988). Increased rate", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 74, "page_number": 57, "text_preview": "Juang, C.-F. (2004). A hybrid of genetic algorithm and particle swarm optimization for recurrent\nnetwork design. Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on,\n34(2):997\u2013100", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 75, "page_number": 58, "text_preview": "In Interna-\ntional Joint Conference on Neural Networks (IJCNN), pages 2849\u20132856. IEEE. Khan, S. H., Bennamoun, M., Sohel, F., and Togneri, R. (2014). Automatic feature learning for robust\nshadow detec", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 76, "page_number": 59, "text_preview": "Kondo, T. (1998). GMDH neural network algorithm using the heuristic self-organization method\nand its application to the pattern identi\ufb01cation problem. In Proceedings of the 37th SICE Annual\nConference", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 77, "page_number": 60, "text_preview": "S., editors, Advances in Neural Information Processing\nSystems 4, pages 950\u2013957. Morgan Kaufmann. Kruger, N., Janssen, P., Kalkan, S., Lappe, M., Leonardis, A., Piater, J., Rodriguez-Sanchez, A., and\n", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 78, "page_number": 61, "text_preview": "S., Henderson, D., Howard, R. E., Hubbard, W., and Jackel, L. D. (1990a). Handwritten digit recognition with a back-propagation network. In Touretzky, D. S.,\neditor, Advances in Neural Information Pro", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 79, "page_number": 61, "text_preview": "61\nLeibniz, G. W. (1676). Memoir using the chain rule (cited in TMME 7:2&3 p 321-332, 2010). Leibniz, G. W. (1684). Nova methodus pro maximis et minimis, itemque tangentibus, quae nec\nfractas, nec irr", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 80, "page_number": 62, "text_preview": "Lindst\u00a8adt, S. (1993). Comparison of two unsupervised neural network models for redundancy reduc-\ntion. In Mozer, M. C., Smolensky, P., Touretzky, D. S., Elman, J. L., and Weigend, A. S., editors,\nPro", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 81, "page_number": 63, "text_preview": "Maas, A. L., Hannun, A. Y., and Ng, A. Y. (2013). Recti\ufb01er nonlinearities improve neural network\nacoustic models. In International Conference on Machine Learning (ICML). Maass, W. (1996). Lower bounds", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 82, "page_number": 64, "text_preview": "Marchi, E., Ferroni, G., Eyben, F., Gabrielli, L., Squartini, S., and Schuller, B. (2014). Multi-\nresolution linear prediction based features for audio onset detection with bidirectional LSTM neural\nn", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 83, "page_number": 65, "text_preview": "Menache, I., Mannor, S., and Shimkin, N. (2002). Q-cut \u2013 dynamic discovery of sub-goals in rein-\nforcement learning. In Proc. ECML\u201902, pages 295\u2013306. Merolla, P. A., Arthur, J. V., Alvarez-Icaza, R., ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 84, "page_number": 66, "text_preview": "A., Kuokka, D. R., Etzioni, O., and Gil, Y. (1989). Explanation-based learning: A problem solving perspective. Arti\ufb01cial Intelligence, 40(1):63\u2013118. Mitchell, T. (1997). Machine Learning. McGraw Hill.", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 85, "page_number": 67, "text_preview": "PhD\nthesis, Department of Computer Sciences, The University of Texas at Austin. Moriarty, D. E. and Miikkulainen, R. (1996). Ef\ufb01cient reinforcement learning through symbiotic\nevolution. Machine Learni", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 86, "page_number": 68, "text_preview": "Neural Networks, IEEE Transactions on, 1(1):4\u201327. Narendra, K. S. and Thathatchar, M. A. L. (1974). Learning automata \u2013 a survey. IEEE Transactions\non Systems, Man, and Cybernetics, 4:323\u2013334. Neal, R", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 87, "page_number": 69, "text_preview": "L. (1994b). Learning and evolution in neural networks. Adaptive\nBehavior, 3(1):5\u201328. Nowak, E., Jurie, F., and Triggs, B. (2006). Sampling strategies for bag-of-features image classi\ufb01ca-\ntion. In Proc", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 88, "page_number": 70, "text_preview": "In Proceedings of the 2012 International Conference on Frontiers\nin Handwriting Recognition, pages 533\u2013537. IEEE Computer Society. Oudeyer, P.-Y., Baranes, A., and Kaplan, F. (2013). Intrinsically mot", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 89, "page_number": 70, "text_preview": "70\nPeng, J. and Williams, R. J. (1996). Incremental multi-step Q-learning. Machine Learning, 22:283\u2013\n290. P\u00b4erez-Ortiz, J. A., Gers, F. A., Eck, D., and Schmidhuber, J. (2003). Kalman \ufb01lters improve L", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 90, "page_number": 71, "text_preview": "Springer. Precup, D., Sutton, R. S., and Singh, S. (1998). Multi-time models for temporally abstract planning. In\nAdvances in Neural Information Processing Systems (NIPS), pages 1050\u20131056. Morgan Kauf", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 91, "page_number": 72, "text_preview": "arXiv preprint arXiv:1403.6382. Rechenberg, I. (1971). Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien der\nbiologischen Evolution. Dissertation. Published 1973 by Fromman-Holzboo", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 92, "page_number": 73, "text_preview": "(1989). Self-organizing semantic maps. Biological Cybernetics,\n61(4):241\u2013254. Robinson, A. J. and Fallside, F. (1987). The utility driven dynamic error propagation network. Tech-\nnical Report CUED/F-I", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 93, "page_number": 74, "text_preview": "and Niranjan, M. (1994). On-line Q-learning using connectionist sytems. Technical\nReport CUED/F-INFENG-TR 166, Cambridge University, UK. Russell, S. J., Norvig, P., Canny, J. F., Malik, J. M., and Edw", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 94, "page_number": 75, "text_preview": "Springer. Schapire, R. E. (1990). The strength of weak learnability. Machine Learning, 5:197\u2013227. Schaul, T. and Schmidhuber, J. (2010). Metalearning. Scholarpedia, 6(5):4650. Schaul, T., Zhang, S., a", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 95, "page_number": 76, "text_preview": "Elsevier Science Publishers B.V., North-Holland. Schmidhuber, J. (1991c). Reinforcement learning in Markovian and non-Markovian environments. In Lippman, D. S., Moody, J. E., and Touretzky, D. S., edi", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 96, "page_number": 77, "text_preview": "(2013b). POWERPLAY: Training an Increasingly General Problem Solver by Con-\ntinually Searching for the Simplest Still Unsolvable Problem. Frontiers in Psychology. Schmidhuber, J., Ciresan, D., Meier, ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 97, "page_number": 78, "text_preview": "N. and Sejnowski, T. J. (1996). Tempering backpropagation networks: Not all\nweights are created equal. In Touretzky, D. S., Mozer, M. C., and Hasselmo, M. E., editors, Ad-\nvances in Neural Information", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 98, "page_number": 79, "text_preview": "Seung, H. S. (2003). Learning in spiking neural networks by reinforcement of stochastic synaptic\ntransmission. Neuron, 40(6):1063\u20131073. Shan, H. and Cottrell, G. (2014). Ef\ufb01cient visual coding: From r", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 99, "page_number": 80, "text_preview": "Smith, S. F. (1980). A Learning System Based on Genetic Adaptive Algorithms,. PhD thesis, Univ. Pittsburgh. Smolensky, P. (1986). Parallel distributed processing: Explorations in the microstructure of", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 100, "page_number": 81, "text_preview": "(1974). Cross-validatory choice and assessment of statistical predictions. Roy. Stat. Soc.,\n36:111\u2013147. Stoop, R., Schindler, K., and Bunimovich, L. (2000). When pyramidal neurons lock, when they\nresp", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 101, "page_number": 81, "text_preview": "(2014). Going deeper with convolutions. Technical Report arXiv:1409.4842 [cs.CV],\nGoogle. Szegedy, C., Toshev, A., and Erhan, D. (2013). Deep neural networks for object detection. pages\n2553\u20132561. 81\n", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 102, "page_number": 82, "text_preview": "J., and McNaughton, B. L. (1996). Population dynam-\nics and theta rhythm phase precession of hippocampal place cell \ufb01ring: a spiking neuron model. Hippocampus, 6(3):271\u2013280. Turaga, S. C., Murray, J. ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 103, "page_number": 83, "text_preview": "(2003). A training algorithm for classi\ufb01cation of high-dimensional data. Neurocomputing, 50:461\u2013472. Viglione, S. (1970). Applications of pattern recognition technology. In Mendel, J. M. and Fu, K. S.", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 104, "page_number": 84, "text_preview": "J., and Lippman, R. P., editors, Advances in Neural\nInformation Processing Systems 4, pages 309\u2013316. Morgan Kaufmann. Waydo, S. and Koch, C. (2008). Unsupervised learning of individuals and categories", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 105, "page_number": 85, "text_preview": "Springer. West, A. H. L. and Saad, D. (1995). Adaptive back-propagation in on-line learning of multilayer\nnetworks. In Touretzky, D. S., Mozer, M., and Hasselmo, M. E., editors, NIPS, pages 323\u2013329. M", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 106, "page_number": 86, "text_preview": "MIT Press. Wilkinson, J. H., editor (1965). The Algebraic Eigenvalue Problem. Oxford University Press, Inc.,\nNew York, NY, USA. Williams, R. J. (1986). Reinforcement-learning in connectionist networks", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 107, "page_number": 87, "text_preview": "H. (1994). Bayesian backpropagation over i-o functions rather than weights. In Cowan,\nJ. D., Tesauro, G., and Alspector, J., editors, Advances in Neural Information Processing Systems\n(NIPS) 6, pages ", "paper_title": "Deep learning in neural networks: An overview"}, {"paper_id": "699d3cdefc47dbc29db48a16", "chunk_index": 108, "page_number": 88, "text_preview": "Zeiler, M. D. and Fergus, R. (2013). Visualizing and understanding convolutional networks. Technical\nReport arXiv:1311.2901 [cs.CV], NYU. Zemel, R. S. (1993). A minimum description length framework fo", "paper_title": "Deep learning in neural networks: An overview"}]}